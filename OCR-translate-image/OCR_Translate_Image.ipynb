{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4zW7orHqwMl"
      },
      "outputs": [],
      "source": [
        "%pip install eyepop==3.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn-EN43rq4I1"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "EYEPOP_ACCOUNT_ID=input(\"Enter your Account UUID: \")\n",
        "EYEPOP_API_KEY=getpass.getpass('Enter your API KEY: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzOBTG_DrWYF"
      },
      "outputs": [],
      "source": [
        "NAMESPACE_PREFIX=\"XXXXXXXXXX\" # Change this to your namespace prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSmUefuIrpDE"
      },
      "outputs": [],
      "source": [
        "from eyepop import EyePopSdk\n",
        "from eyepop.data.data_types import InferRuntimeConfig, VlmAbilityGroupCreate, VlmAbilityCreate, TransformInto\n",
        "from eyepop.worker.worker_types import CropForward, ForwardComponent, FullForward, InferenceComponent, Pop\n",
        "import json\n",
        "\n",
        "\n",
        "ability_prototypes = [\n",
        "    VlmAbilityCreate(\n",
        "        name=f\"{NAMESPACE_PREFIX}.image-describe.OCR-Translate-Image\",\n",
        "        description=\"Translate the text into English\",\n",
        "        worker_release=\"qwen3-instruct\",\n",
        "        text_prompt=\"\"\"\n",
        "          You are given a single image that may contain text in any language.\n",
        "          Your task is to read ALL legible text in the image and translate it into English.\n",
        "          Return ONLY valid JSON.\n",
        "          Do not include explanation.\n",
        "          Do not include markdown.\n",
        "          Do not include commentary.\n",
        "          ----------------------------------------\n",
        "          INSTRUCTIONS:\n",
        "          1. Extract only text that is clearly readable in the image.\n",
        "          2. Preserve the original reading order as it appears visually:\n",
        "            - Top to bottom\n",
        "            - Left to right\n",
        "            - Group by regions/blocks (e.g., headings, paragraphs, labels, signs).\n",
        "          3. Do NOT guess missing characters or words.\n",
        "          4. If a portion is partially unreadable, include the readable part and use \"â€¦\" to mark missing content.\n",
        "          5. Keep numbers, dates, emails, URLs, product codes exactly as shown.\n",
        "          6. If text is already English, still return it as the translation.\n",
        "          7. If no readable text is present, return:\n",
        "          {\n",
        "            \"has_text\": false,\n",
        "            \"detected_language\": null,\n",
        "            \"blocks\": [],\n",
        "            \"full_translation\": null\n",
        "          }\n",
        "          ----------------------------------------\n",
        "          RETURN THIS EXACT JSON STRUCTURE:\n",
        "          {\n",
        "            \"has_text\": true,\n",
        "            \"detected_language\": null,\n",
        "            \"blocks\": [\n",
        "              {\n",
        "                \"block_id\": 1,\n",
        "                \"original_text\": null,\n",
        "                \"english_translation\": null\n",
        "              }\n",
        "            ],\n",
        "            \"full_translation\": null\n",
        "          }\n",
        "          ----------------------------------------\n",
        "          FIELD RULES:\n",
        "          - detected_language: set to the best single language label if clear (e.g., \"Spanish\", \"French\", \"Japanese\"); otherwise null.\n",
        "          - blocks: include one entry per visually distinct text block (title, label cluster, paragraph, sign panel, etc.).\n",
        "          - original_text: the exact extracted text for that block (preserve line breaks if visible).\n",
        "          - english_translation: a faithful English translation of that block.\n",
        "          - full_translation: concatenate english_translation from all blocks in order, separated by newline characters.\n",
        "          ----------------------------------------\n",
        "          STRICT OUTPUT RULES:\n",
        "          - Output must be strict JSON (double quotes, no trailing commas).\n",
        "          - Do not include any additional keys.\n",
        "          - Do not wrap in code fences.\n",
        "          Return only the JSON object.\n",
        "        \"\"\",\n",
        "        transform_into=TransformInto(),\n",
        "        config=InferRuntimeConfig(\n",
        "            max_new_tokens=250,\n",
        "            image_size=512\n",
        "        ),\n",
        "        is_public=False\n",
        "    )\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWx1MPOzsYMf"
      },
      "outputs": [],
      "source": [
        "with EyePopSdk.dataEndpoint(api_key=EYEPOP_API_KEY, account_id=EYEPOP_ACCOUNT_ID) as endpoint:\n",
        "    for ability_prototype in ability_prototypes:\n",
        "        ability_group = endpoint.create_vlm_ability_group(VlmAbilityGroupCreate(\n",
        "            name=ability_prototype.name,\n",
        "            description=ability_prototype.description,\n",
        "            default_alias_name=ability_prototype.name,\n",
        "        ))\n",
        "        ability = endpoint.create_vlm_ability(\n",
        "            create=ability_prototype,\n",
        "            vlm_ability_group_uuid=ability_group.uuid,\n",
        "        )\n",
        "        ability = endpoint.publish_vlm_ability(\n",
        "            vlm_ability_uuid=ability.uuid,\n",
        "            alias_name=ability_prototype.name,\n",
        "        )\n",
        "        ability = endpoint.add_vlm_ability_alias(\n",
        "            vlm_ability_uuid=ability.uuid,\n",
        "            alias_name=ability_prototype.name,\n",
        "            tag_name=\"latest\"\n",
        "        )\n",
        "        print(f\"created ability {ability.uuid} with alias entries {ability.alias_entries}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFH_qGp2wUu"
      },
      "source": [
        "### Evalulate on a Single Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HczHIz-2xQO"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "pop = Pop(components=[\n",
        "   InferenceComponent(\n",
        "       ability=f\"{NAMESPACE_PREFIX}.image-describe.OCR-Translate-Image:latest\"\n",
        "   )\n",
        "])\n",
        "\n",
        "\n",
        "with EyePopSdk.workerEndpoint(api_key=EYEPOP_API_KEY) as endpoint:\n",
        "   endpoint.set_pop(pop)\n",
        "   sample_img_path = Path(\"/content/images.jpeg\")\n",
        "   job = endpoint.upload(sample_img_path)\n",
        "   while result := job.predict():\n",
        "      print(json.dumps(result, indent=2))\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH1lrPMKtXWe"
      },
      "source": [
        "### Evaluation Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2gDyJiAs4FB"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "pop = Pop(components=[\n",
        "    InferenceComponent(\n",
        "        ability=f\"{NAMESPACE_PREFIX}.image-describe.OCR-Translate-Image:latest\"\n",
        "    )\n",
        "])\n",
        "\n",
        "all_results = {}\n",
        "\n",
        "with EyePopSdk.workerEndpoint(api_key=EYEPOP_API_KEY) as endpoint:\n",
        "    endpoint.set_pop(pop)\n",
        "    directory_path = Path(\"/content/\")\n",
        "\n",
        "    for item in directory_path.iterdir():\n",
        "        job = endpoint.upload(str(item))\n",
        "        file_results = []\n",
        "        while result := job.predict():\n",
        "            file_results.append(result)\n",
        "\n",
        "        all_results[item.name] = file_results\n",
        "\n",
        "output_path = Path(\"/content/sample_data/output.json\")\n",
        "with open(output_path, \"w\") as f:\n",
        "  json.dump(all_results, f, indent=2)\n",
        "\n",
        "print(\"Done\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
